{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import tkinter.messagebox\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phuongdong/miniconda3/envs/voice/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.preprocessing.data module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/phuongdong/miniconda3/envs/voice/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.mixture.gaussian_mixture module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.mixture. Anything that cannot be imported from sklearn.mixture is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from nnmnkwii.datasets import PaddedFileSourceDataset\n",
    "from nnmnkwii.datasets.cmu_arctic import CMUArcticWavFileDataSource\n",
    "from nnmnkwii.preprocessing.alignment import DTWAligner\n",
    "from nnmnkwii.preprocessing import trim_zeros_frames, remove_zeros_frames, delta_features\n",
    "from nnmnkwii.util import apply_each2d_trim\n",
    "from nnmnkwii.metrics import melcd\n",
    "from nnmnkwii.baseline.gmm import MLPG\n",
    "\n",
    "from os.path import basename, splitext\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyworld\n",
    "import pysptk\n",
    "from pysptk.synthesis import MLSADF, Synthesizer\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "FILE_NAME = 'input/voice.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "recording = 0\n",
    "frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_record():\n",
    "    recording = 1\n",
    "    frames.clear()\n",
    "    label['text'] = 'Đang ghi âm'\n",
    "    stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "    while recording == 1:\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        window.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_record(): \n",
    "    recording = 0\n",
    "    label['text'] = 'Ghi âm xong'\n",
    "    print('* stop recording')\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    wf = wave.open(FILE_NAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_wav(c):\n",
    "    p_read = pyaudio.PyAudio()\n",
    "    wf_read = wave.open(c, 'rb')\n",
    "    stream_read = p_read.open(format =\n",
    "                            p_read.get_format_from_width(wf_read.getsampwidth()),\n",
    "                            channels = wf_read.getnchannels(),\n",
    "                            rate = wf_read.getframerate(),\n",
    "                            output = True)\n",
    "    data = wf_read.readframes(CHUNK)\n",
    "    while data != '':\n",
    "        # writing to the stream is what *actually* plays the sound.\n",
    "        stream_read.write(data)\n",
    "        data = wf_read.readframes(CHUNK)\n",
    "        window.update()\n",
    "    stream_read.close()    \n",
    "    p_read.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs =44100\n",
    "fftlen = pyworld.get_cheaptrick_fft_size(fs)\n",
    "alpha = pysptk.util.mcepalpha(fs)\n",
    "order = 24\n",
    "frame_period = 5\n",
    "hop_length = int(fs * (frame_period * 0.001))\n",
    "max_files = 100 # number of utterances to be used.\n",
    "test_size = 0.03\n",
    "use_delta = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_delta:\n",
    "    windows = [\n",
    "        (0, 0, np.array([1.0])),\n",
    "        (1, 1, np.array([-0.5, 0.0, 0.5])),\n",
    "        (1, 1, np.array([1.0, -2.0, 1.0])),\n",
    "    ]\n",
    "else:\n",
    "    windows = [\n",
    "        (0, 0, np.array([1.0])),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/quang.pkl\", \"rb\") as file: \n",
    "    gmm=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_model(c):\n",
    "    title_model['text'] = c\n",
    "    with open(\"models/\" + c + \".pkl\", \"rb\") as file: \n",
    "        gmm=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_utt(src_path, disable_mlpg=False, diffvc=True):\n",
    "    # GMM-based parameter generation is provided by the library in `baseline` module\n",
    "    if disable_mlpg:\n",
    "        # Force disable MLPG\n",
    "        paramgen = MLPG(gmm, windows=[(0,0, np.array([1.0]))], diff=diffvc)\n",
    "    else:\n",
    "        paramgen = MLPG(gmm, windows=windows, diff=diffvc)\n",
    "\n",
    "    fs, x = wavfile.read(src_path)\n",
    "    print(x)\n",
    "    x = x.astype(np.float64)\n",
    "    if len(x.shape)==2:\n",
    "        x=x.sum(axis=1)/2\n",
    "    f0, timeaxis = pyworld.dio(x, fs, frame_period=frame_period)\n",
    "    f0 = pyworld.stonemask(x, f0, timeaxis, fs)\n",
    "    spectrogram = pyworld.cheaptrick(x, f0, timeaxis, fs)\n",
    "    aperiodicity = pyworld.d4c(x, f0, timeaxis, fs)\n",
    "\n",
    "    mc = pysptk.sp2mc(spectrogram, order=order, alpha=alpha)\n",
    "    c0, mc = mc[:, 0], mc[:, 1:]\n",
    "    if use_delta:\n",
    "        mc = delta_features(mc, windows)\n",
    "    mc = paramgen.transform(mc)\n",
    "    #if disable_mlpg and mc.shape[-1] != static_dim:\n",
    "    #    mc = mc[:,:static_dim]\n",
    "    #assert mc.shape[-1] == static_dim\n",
    "    mc = np.hstack((c0[:, None], mc))\n",
    "    if diffvc:\n",
    "        mc[:, 0] = 0 # remove power coefficients\n",
    "        engine = Synthesizer(MLSADF(order=order, alpha=alpha), hopsize=hop_length)\n",
    "        b = pysptk.mc2b(mc.astype(np.float64), alpha=alpha)\n",
    "        waveform = engine.synthesis(x, b)\n",
    "    else:\n",
    "        spectrogram = pysptk.mc2sp(\n",
    "            mc.astype(np.float64), alpha=alpha, fftlen=fftlen)\n",
    "        waveform = pyworld.synthesize(\n",
    "            f0, spectrogram, aperiodicity, fs, frame_period)\n",
    "        \n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vc():\n",
    "    src_path=\"input/voice.wav\"\n",
    "    tgt_path=\"output/voice.wav\"\n",
    "    w_MLPG = test_one_utt(src_path, disable_mlpg=False)\n",
    "    wavfile.write(tgt_path,fs,w_MLPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2461 -1947 -1919 ...  3051  2622  2451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-24-afa9a2586ce2>\", line 5, in vc\n",
      "    wave.open(tgt_path, 'wb').writeframesraw(w_MLPG)\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 416, in writeframesraw\n",
      "    self._ensure_header_written(len(data))\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 452, in _ensure_header_written\n",
      "    raise Error('# channels not specified')\n",
      "wave.Error: # channels not specified\n",
      "Exception in Tkinter callback\n",
      "Exception ignored in: <bound method Wave_write.__del__ of <wave.Wave_write object at 0x7fb0063dd908>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 316, in __del__\n",
      "    self.close()\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 434, in close\n",
      "    self._ensure_header_written(0)\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 452, in _ensure_header_written\n",
      "    raise Error('# channels not specified')\n",
      "wave.Error: # channels not specified\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-25-a8ec0f72c83e>\", line 30, in <lambda>\n",
      "    button_play_2 = tk.Button(window, text='Kiểm tra', width=15, command=lambda c='output/voice.wav': play_wav(c))\n",
      "  File \"<ipython-input-10-2a6a66e7da40>\", line 3, in play_wav\n",
      "    wf_read = wave.open(c, 'rb')\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 499, in open\n",
      "    return Wave_read(f)\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 163, in __init__\n",
      "    self.initfp(f)\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/wave.py\", line 128, in initfp\n",
      "    self._file = Chunk(file, bigendian = 0)\n",
      "  File \"/home/phuongdong/miniconda3/envs/voice/lib/python3.6/chunk.py\", line 63, in __init__\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "window = tk.Tk()\n",
    "window.geometry('500x300')\n",
    "window.title('Voice conversion')\n",
    "model_names = [\n",
    "    'dong',\n",
    "    'quang',\n",
    "    'duc',\n",
    "    'an',\n",
    "    'tuyen',\n",
    "    'thang'\n",
    "]\n",
    "button_model = tk.Frame(window, padx=150, pady=100)\n",
    "button_model.pack(fill=BOTH)\n",
    "title_model = Menubutton(button_model, width=20, padx=10,\n",
    "                                pady=5, relief=RAISED)\n",
    "title_model.grid(row=0, column=0, padx=20, pady=5)\n",
    "title_model['text'] = 'Chọn giọng chuyển'\n",
    "title_model.menu = Menu(title_model)\n",
    "title_model[\"menu\"] = title_model.menu\n",
    "for c in model_names:\n",
    "    title_model.menu.add_command(label=c, command=lambda c=c: import_model(c))\n",
    "button_start = tk.Button(window, text='Ghi âm', width=15, command=start_record)\n",
    "button_start.place(x=70, y=50)\n",
    "button_stop = tk.Button(window, text='Dừng ghi âm', width=15, command=stop_record)\n",
    "button_stop.place(x=190, y=50)\n",
    "button_play = tk.Button(window, text='Phát lại', width=15, command=lambda c='input/voice.wav': play_wav(c))\n",
    "button_play.place(x=310, y=50)\n",
    "button_vc = tk.Button(window, text='Chuyển giọng', width=15, command=vc)\n",
    "button_vc.place(x=130, y=150)\n",
    "button_play_2 = tk.Button(window, text='Kiểm tra', width=15, command=lambda c='output/voice.wav': play_wav(c))\n",
    "button_play_2.place(x=250, y=150)\n",
    "label = tk.Label(window)\n",
    "label.place(x=220, y=200)\n",
    "tk.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
